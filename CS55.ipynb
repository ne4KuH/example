{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":8363314,"sourceType":"datasetVersion","datasetId":4968460}],"dockerImageVersionId":30698,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\n# import os\n# for dirname, _, filenames in os.walk('/kaggle/input'):\n#     for filename in filenames:\n#         print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","_kg_hide-output":true,"execution":{"iopub.status.busy":"2024-05-11T14:29:55.550281Z","iopub.execute_input":"2024-05-11T14:29:55.550696Z","iopub.status.idle":"2024-05-11T14:29:56.476238Z","shell.execute_reply.started":"2024-05-11T14:29:55.550661Z","shell.execute_reply":"2024-05-11T14:29:56.475093Z"},"trusted":true},"execution_count":1,"outputs":[]},{"cell_type":"code","source":"import os\nimport shutil\n\n# Define the directories for images and labels\nbase_dir = '/kaggle/input/dataset-cvat/images/default'\nimages_dir = '/kaggle/working/images'\nlabels_dir = '/kaggle/working/labels'\n\n# Create directories if they do not exist\nos.makedirs(images_dir, exist_ok=True)\nos.makedirs(labels_dir, exist_ok=True)\n\n# Copy images to the images directory and labels to the labels directory\nfor filename in os.listdir(base_dir):\n    if filename.endswith('.jpg') or filename.endswith('.jpeg') or filename.endswith('.png'):\n        shutil.copy(os.path.join(base_dir, filename), os.path.join(images_dir, filename))\n    elif filename.endswith('.txt'):\n        shutil.copy(os.path.join(base_dir, filename), os.path.join(labels_dir, filename))\n","metadata":{"execution":{"iopub.status.busy":"2024-05-11T14:29:56.478541Z","iopub.execute_input":"2024-05-11T14:29:56.479319Z","iopub.status.idle":"2024-05-11T14:30:14.652295Z","shell.execute_reply.started":"2024-05-11T14:29:56.479284Z","shell.execute_reply":"2024-05-11T14:30:14.651535Z"},"trusted":true},"execution_count":2,"outputs":[]},{"cell_type":"code","source":"from sklearn.model_selection import train_test_split\nimport numpy as np\n\n# List all images\nimage_files = [f for f in os.listdir(images_dir) if f.endswith(('.jpg', '.jpeg', '.png'))]\n# Corresponding label files\nlabel_files = [f'{os.path.splitext(f)[0]}.txt' for f in image_files]\n\n# Split the dataset into training and validation sets\ntrain_images, val_images, train_labels, val_labels = train_test_split(\n    image_files, label_files, test_size=0.2, random_state=42)\n\n# Function to move files\ndef move_files(files, source_dir, target_dir):\n    for f in files:\n        shutil.move(os.path.join(source_dir, f), os.path.join(target_dir, f))\n\n# Create directories for the train and validation splits\ntrain_images_dir = '/kaggle/working/train/images'\ntrain_labels_dir = '/kaggle/working/train/labels'\nval_images_dir = '/kaggle/working/val/images'\nval_labels_dir = '/kaggle/working/val/labels'\n\nos.makedirs(train_images_dir, exist_ok=True)\nos.makedirs(train_labels_dir, exist_ok=True)\nos.makedirs(val_images_dir, exist_ok=True)\nos.makedirs(val_labels_dir, exist_ok=True)\n\n# Move the files\nmove_files(train_images, images_dir, train_images_dir)\nmove_files(train_labels, labels_dir, train_labels_dir)\nmove_files(val_images, images_dir, val_images_dir)\nmove_files(val_labels, labels_dir, val_labels_dir)\n","metadata":{"execution":{"iopub.status.busy":"2024-05-11T14:30:14.653430Z","iopub.execute_input":"2024-05-11T14:30:14.653749Z","iopub.status.idle":"2024-05-11T14:30:15.213870Z","shell.execute_reply.started":"2024-05-11T14:30:14.653723Z","shell.execute_reply":"2024-05-11T14:30:15.213017Z"},"trusted":true},"execution_count":3,"outputs":[]},{"cell_type":"code","source":"%cd /kaggle/working/\n!mkdir tmp\n%cd tmp","metadata":{"execution":{"iopub.status.busy":"2024-05-11T14:30:15.216152Z","iopub.execute_input":"2024-05-11T14:30:15.216455Z","iopub.status.idle":"2024-05-11T14:30:16.175008Z","shell.execute_reply.started":"2024-05-11T14:30:15.216429Z","shell.execute_reply":"2024-05-11T14:30:16.173883Z"},"trusted":true},"execution_count":4,"outputs":[{"name":"stdout","text":"/kaggle/working\n/kaggle/working/tmp\n","output_type":"stream"}]},{"cell_type":"code","source":"# Install YOLOv5 dependencies from the official repository\n!git clone https://github.com/ultralytics/yolov5  # clone repo\n%cd yolov5\n!pip install -r requirements.txt  # install dependencies\n","metadata":{"execution":{"iopub.status.busy":"2024-05-11T14:30:16.176595Z","iopub.execute_input":"2024-05-11T14:30:16.176990Z","iopub.status.idle":"2024-05-11T14:30:37.830001Z","shell.execute_reply.started":"2024-05-11T14:30:16.176936Z","shell.execute_reply":"2024-05-11T14:30:37.829060Z"},"trusted":true},"execution_count":5,"outputs":[{"name":"stdout","text":"Cloning into 'yolov5'...\nremote: Enumerating objects: 16582, done.\u001b[K\nremote: Counting objects: 100% (60/60), done.\u001b[K\nremote: Compressing objects: 100% (42/42), done.\u001b[K\nremote: Total 16582 (delta 30), reused 39 (delta 18), pack-reused 16522\u001b[K\nReceiving objects: 100% (16582/16582), 15.13 MiB | 30.92 MiB/s, done.\nResolving deltas: 100% (11387/11387), done.\n/kaggle/working/tmp/yolov5\nRequirement already satisfied: gitpython>=3.1.30 in /opt/conda/lib/python3.10/site-packages (from -r requirements.txt (line 5)) (3.1.41)\nRequirement already satisfied: matplotlib>=3.3 in /opt/conda/lib/python3.10/site-packages (from -r requirements.txt (line 6)) (3.7.5)\nRequirement already satisfied: numpy>=1.23.5 in /opt/conda/lib/python3.10/site-packages (from -r requirements.txt (line 7)) (1.26.4)\nRequirement already satisfied: opencv-python>=4.1.1 in /opt/conda/lib/python3.10/site-packages (from -r requirements.txt (line 8)) (4.9.0.80)\nCollecting pillow>=10.3.0 (from -r requirements.txt (line 9))\n  Downloading pillow-10.3.0-cp310-cp310-manylinux_2_28_x86_64.whl.metadata (9.2 kB)\nRequirement already satisfied: psutil in /opt/conda/lib/python3.10/site-packages (from -r requirements.txt (line 10)) (5.9.3)\nRequirement already satisfied: PyYAML>=5.3.1 in /opt/conda/lib/python3.10/site-packages (from -r requirements.txt (line 11)) (6.0.1)\nRequirement already satisfied: requests>=2.23.0 in /opt/conda/lib/python3.10/site-packages (from -r requirements.txt (line 12)) (2.31.0)\nRequirement already satisfied: scipy>=1.4.1 in /opt/conda/lib/python3.10/site-packages (from -r requirements.txt (line 13)) (1.11.4)\nCollecting thop>=0.1.1 (from -r requirements.txt (line 14))\n  Downloading thop-0.1.1.post2209072238-py3-none-any.whl.metadata (2.7 kB)\nRequirement already satisfied: torch>=1.8.0 in /opt/conda/lib/python3.10/site-packages (from -r requirements.txt (line 15)) (2.1.2)\nRequirement already satisfied: torchvision>=0.9.0 in /opt/conda/lib/python3.10/site-packages (from -r requirements.txt (line 16)) (0.16.2)\nRequirement already satisfied: tqdm>=4.64.0 in /opt/conda/lib/python3.10/site-packages (from -r requirements.txt (line 17)) (4.66.1)\nCollecting ultralytics>=8.0.232 (from -r requirements.txt (line 18))\n  Downloading ultralytics-8.2.12-py3-none-any.whl.metadata (40 kB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m40.7/40.7 kB\u001b[0m \u001b[31m1.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hRequirement already satisfied: pandas>=1.1.4 in /opt/conda/lib/python3.10/site-packages (from -r requirements.txt (line 27)) (2.1.4)\nRequirement already satisfied: seaborn>=0.11.0 in /opt/conda/lib/python3.10/site-packages (from -r requirements.txt (line 28)) (0.12.2)\nRequirement already satisfied: setuptools>=65.5.1 in /opt/conda/lib/python3.10/site-packages (from -r requirements.txt (line 42)) (69.0.3)\nRequirement already satisfied: wheel>=0.38.0 in /opt/conda/lib/python3.10/site-packages (from -r requirements.txt (line 50)) (0.42.0)\nRequirement already satisfied: gitdb<5,>=4.0.1 in /opt/conda/lib/python3.10/site-packages (from gitpython>=3.1.30->-r requirements.txt (line 5)) (4.0.11)\nRequirement already satisfied: contourpy>=1.0.1 in /opt/conda/lib/python3.10/site-packages (from matplotlib>=3.3->-r requirements.txt (line 6)) (1.2.0)\nRequirement already satisfied: cycler>=0.10 in /opt/conda/lib/python3.10/site-packages (from matplotlib>=3.3->-r requirements.txt (line 6)) (0.12.1)\nRequirement already satisfied: fonttools>=4.22.0 in /opt/conda/lib/python3.10/site-packages (from matplotlib>=3.3->-r requirements.txt (line 6)) (4.47.0)\nRequirement already satisfied: kiwisolver>=1.0.1 in /opt/conda/lib/python3.10/site-packages (from matplotlib>=3.3->-r requirements.txt (line 6)) (1.4.5)\nRequirement already satisfied: packaging>=20.0 in /opt/conda/lib/python3.10/site-packages (from matplotlib>=3.3->-r requirements.txt (line 6)) (21.3)\nRequirement already satisfied: pyparsing>=2.3.1 in /opt/conda/lib/python3.10/site-packages (from matplotlib>=3.3->-r requirements.txt (line 6)) (3.1.1)\nRequirement already satisfied: python-dateutil>=2.7 in /opt/conda/lib/python3.10/site-packages (from matplotlib>=3.3->-r requirements.txt (line 6)) (2.9.0.post0)\nRequirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests>=2.23.0->-r requirements.txt (line 12)) (3.3.2)\nRequirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests>=2.23.0->-r requirements.txt (line 12)) (3.6)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests>=2.23.0->-r requirements.txt (line 12)) (1.26.18)\nRequirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests>=2.23.0->-r requirements.txt (line 12)) (2024.2.2)\nRequirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from torch>=1.8.0->-r requirements.txt (line 15)) (3.13.1)\nRequirement already satisfied: typing-extensions in /opt/conda/lib/python3.10/site-packages (from torch>=1.8.0->-r requirements.txt (line 15)) (4.9.0)\nRequirement already satisfied: sympy in /opt/conda/lib/python3.10/site-packages (from torch>=1.8.0->-r requirements.txt (line 15)) (1.12)\nRequirement already satisfied: networkx in /opt/conda/lib/python3.10/site-packages (from torch>=1.8.0->-r requirements.txt (line 15)) (3.2.1)\nRequirement already satisfied: jinja2 in /opt/conda/lib/python3.10/site-packages (from torch>=1.8.0->-r requirements.txt (line 15)) (3.1.2)\nRequirement already satisfied: fsspec in /opt/conda/lib/python3.10/site-packages (from torch>=1.8.0->-r requirements.txt (line 15)) (2024.2.0)\nRequirement already satisfied: py-cpuinfo in /opt/conda/lib/python3.10/site-packages (from ultralytics>=8.0.232->-r requirements.txt (line 18)) (9.0.0)\nRequirement already satisfied: pytz>=2020.1 in /opt/conda/lib/python3.10/site-packages (from pandas>=1.1.4->-r requirements.txt (line 27)) (2023.3.post1)\nRequirement already satisfied: tzdata>=2022.1 in /opt/conda/lib/python3.10/site-packages (from pandas>=1.1.4->-r requirements.txt (line 27)) (2023.4)\nRequirement already satisfied: smmap<6,>=3.0.1 in /opt/conda/lib/python3.10/site-packages (from gitdb<5,>=4.0.1->gitpython>=3.1.30->-r requirements.txt (line 5)) (5.0.1)\nRequirement already satisfied: six>=1.5 in /opt/conda/lib/python3.10/site-packages (from python-dateutil>=2.7->matplotlib>=3.3->-r requirements.txt (line 6)) (1.16.0)\nRequirement already satisfied: MarkupSafe>=2.0 in /opt/conda/lib/python3.10/site-packages (from jinja2->torch>=1.8.0->-r requirements.txt (line 15)) (2.1.3)\nRequirement already satisfied: mpmath>=0.19 in /opt/conda/lib/python3.10/site-packages (from sympy->torch>=1.8.0->-r requirements.txt (line 15)) (1.3.0)\nDownloading pillow-10.3.0-cp310-cp310-manylinux_2_28_x86_64.whl (4.5 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.5/4.5 MB\u001b[0m \u001b[31m56.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading thop-0.1.1.post2209072238-py3-none-any.whl (15 kB)\nDownloading ultralytics-8.2.12-py3-none-any.whl (756 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m756.4/756.4 kB\u001b[0m \u001b[31m40.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hInstalling collected packages: pillow, thop, ultralytics\n  Attempting uninstall: pillow\n    Found existing installation: Pillow 9.5.0\n    Uninstalling Pillow-9.5.0:\n      Successfully uninstalled Pillow-9.5.0\n\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\nspopt 0.6.0 requires shapely>=2.0.1, but you have shapely 1.8.5.post1 which is incompatible.\nydata-profiling 4.6.4 requires numpy<1.26,>=1.16.0, but you have numpy 1.26.4 which is incompatible.\u001b[0m\u001b[31m\n\u001b[0mSuccessfully installed pillow-10.3.0 thop-0.1.1.post2209072238 ultralytics-8.2.12\n","output_type":"stream"}]},{"cell_type":"code","source":"import torch\nfrom IPython.display import Image, clear_output  # to display images\nimport numpy as np\nimport xml.etree.ElementTree as ET\nfrom os.path import join\nimport os\nimport cv2","metadata":{"execution":{"iopub.status.busy":"2024-05-11T14:30:37.831818Z","iopub.execute_input":"2024-05-11T14:30:37.832215Z","iopub.status.idle":"2024-05-11T14:30:41.354712Z","shell.execute_reply.started":"2024-05-11T14:30:37.832174Z","shell.execute_reply":"2024-05-11T14:30:41.353806Z"},"trusted":true},"execution_count":6,"outputs":[]},{"cell_type":"code","source":"def replace_extension(filename):\n    # This will handle both .png and .jpg files and replace them with .txt\n    base, ext = os.path.splitext(filename)\n    if ext.lower() in ['.png', '.jpg', '.jpeg']:\n        return base + '.txt'\n    return filename\n\n\ndef parse_xml_to_dict(xml_file):\n    tree = ET.parse(xml_file)\n    root = tree.getroot()\n\n    annotations = []\n    for image in root.findall('image'):\n        width = int(image.get('width'))\n        height = int(image.get('height'))\n        filename = image.get('name')\n\n        for poly in image.findall('.//polygon'):\n            points = poly.get('points').split(';')\n            x_coords = []\n            y_coords = []\n            for point in points:\n                x, y = map(float, point.split(','))\n                x_coords.append(x)\n                y_coords.append(y)\n\n            # Calculate the bounding box\n            xmin = min(x_coords)\n            xmax = max(x_coords)\n            ymin = min(y_coords)\n            ymax = max(y_coords)\n\n            # Convert to YOLO format\n            x_center = ((xmin + xmax) / 2) / width\n            y_center = ((ymin + ymax) / 2) / height\n            box_width = (xmax - xmin) / width\n            box_height = (ymax - ymin) / height\n\n            label = poly.get('label').lower()  # Assuming class labels are consistent and correctly mapped\n            annotations.append((filename, label, x_center, y_center, box_width, box_height))\n\n    return annotations\n\ndef save_annotations_to_txt(annotations, output_dir, class_dict):\n    for annotation in annotations:\n        filename, label, x_center, y_center, box_width, box_height = annotation\n        label_idx = class_dict[label]\n        yolo_format = f\"{label_idx} {x_center:.6f} {y_center:.6f} {box_width:.6f} {box_height:.6f}\\n\"\n        \n        txt_filename = replace_extension(filename)\n        txt_path = join(output_dir, txt_filename)\n\n        with open(txt_path, 'a') as file:\n            file.write(yolo_format)\n\n# Define your class labels and corresponding indices\nclass_dict = {'building': 0, 'damage': 1, 'roof': 2, 'damaged roof': 3, 'broken window': 4, 'other': 5}","metadata":{"execution":{"iopub.status.busy":"2024-05-11T14:30:41.356120Z","iopub.execute_input":"2024-05-11T14:30:41.356741Z","iopub.status.idle":"2024-05-11T14:30:41.372941Z","shell.execute_reply.started":"2024-05-11T14:30:41.356698Z","shell.execute_reply":"2024-05-11T14:30:41.370960Z"},"trusted":true},"execution_count":7,"outputs":[]},{"cell_type":"code","source":"# Set paths\nxml_file_path = '/kaggle/input/dataset-cvat/annotations.xml'\nimg_dir = '/kaggle/input/dataset-cvat/images/default'\noutput_dir = 'yolo_format'\n# Create output directory if it doesn't exist\nif not os.path.exists(output_dir):\n    os.makedirs(output_dir)\n\n# Parse XML file\nannotations = parse_xml_to_dict(xml_file_path)\n\n# Save annotations in YOLO format\nsave_annotations_to_txt(annotations, output_dir, class_dict)\n\n","metadata":{"execution":{"iopub.status.busy":"2024-05-11T14:30:41.374291Z","iopub.execute_input":"2024-05-11T14:30:41.374656Z","iopub.status.idle":"2024-05-11T14:30:42.117416Z","shell.execute_reply.started":"2024-05-11T14:30:41.374622Z","shell.execute_reply":"2024-05-11T14:30:42.116545Z"},"trusted":true},"execution_count":8,"outputs":[]},{"cell_type":"code","source":"import yaml\n","metadata":{"execution":{"iopub.status.busy":"2024-05-11T14:30:42.118548Z","iopub.execute_input":"2024-05-11T14:30:42.118836Z","iopub.status.idle":"2024-05-11T14:30:42.145032Z","shell.execute_reply.started":"2024-05-11T14:30:42.118809Z","shell.execute_reply":"2024-05-11T14:30:42.144262Z"},"trusted":true},"execution_count":9,"outputs":[]},{"cell_type":"code","source":"%cp -r /kaggle/working/tmp","metadata":{"execution":{"iopub.status.busy":"2024-05-11T14:30:42.147624Z","iopub.execute_input":"2024-05-11T14:30:42.147894Z","iopub.status.idle":"2024-05-11T14:30:43.115257Z","shell.execute_reply.started":"2024-05-11T14:30:42.147870Z","shell.execute_reply":"2024-05-11T14:30:43.114251Z"},"trusted":true},"execution_count":10,"outputs":[{"name":"stdout","text":"cp: missing destination file operand after '/kaggle/working/tmp'\nTry 'cp --help' for more information.\n","output_type":"stream"}]},{"cell_type":"code","source":"training_dir = '/kaggle/working/train'\nvalidation_dir = '/kaggle/working/val' \ndata_yaml = dict(\n    train = training_dir,\n    val = validation_dir,\n    nc = 6,  # Number of classes\n    names = ['building', 'damage', 'roof', 'damaged roof', 'broken window', 'other']  # Class names\n)\n\nwith open('data.yaml', 'w') as outfile:\n    yaml.dump(data_yaml, outfile, default_flow_style=True)\n","metadata":{"execution":{"iopub.status.busy":"2024-05-11T14:30:43.116681Z","iopub.execute_input":"2024-05-11T14:30:43.117003Z","iopub.status.idle":"2024-05-11T14:30:43.124724Z","shell.execute_reply.started":"2024-05-11T14:30:43.116963Z","shell.execute_reply":"2024-05-11T14:30:43.123866Z"},"trusted":true},"execution_count":11,"outputs":[]},{"cell_type":"code","source":"import os\nos.environ['WANDB_MODE'] = 'disabled'  # Disable WandB\n!python train.py --img 640 --batch 16 --epochs 50 --data data.yaml --weights yolov5s.pt --cache","metadata":{"execution":{"iopub.status.busy":"2024-05-11T14:30:43.125807Z","iopub.execute_input":"2024-05-11T14:30:43.126061Z"},"trusted":true},"execution_count":null,"outputs":[{"name":"stdout","text":"\u001b[34m\u001b[1mwandb\u001b[0m: WARNING ⚠️ wandb is deprecated and will be removed in a future release. See supported integrations at https://github.com/ultralytics/yolov5#integrations.\n2024-05-11 14:30:54.001893: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n2024-05-11 14:30:54.001994: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n","output_type":"stream"}]},{"cell_type":"code","source":"# Load the trained model\nmodel = torch.hub.load('ultralytics/yolov5', 'custom', path='runs/train/exp/weights/best.pt')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Use in case of inference on a single image\n# Set the path to an image\nimg_path = '/kaggle/working/val/images/download10_2.png'\n\n# Inference\nresults = model(img_path)\nresults.print()  # Print results\n\n# Display the image with bounding boxes\nresults.show()  # Display the image with bounding boxes","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Same inference as above\n# !python detect.py --weights runs/train/exp/weights/best.pt --conf 0.5 --img-size 640 --source /kaggle/working/val/images/image7_1.png","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}